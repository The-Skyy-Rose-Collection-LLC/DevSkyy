base_model: Qwen/Qwen2.5-1.5B-Instruct
batch_size: 2
block_size: 1024
chat_template: chatml
data_path: damBruh/skyyrose-brand-voice-training
gradient_accumulation: 4
hub_model: damBruh/skyyrose-brand-voice-llm
learning_rate: 0.0002
lora_alpha: 32
lora_r: 16
num_epochs: 3
peft: true
project_name: skyyrose-brand-voice
quantization: int4
target_modules: all-linear
task: llm:sft
text_column: messages
train_split: train
warmup_ratio: 0.1
weight_decay: 0.01
