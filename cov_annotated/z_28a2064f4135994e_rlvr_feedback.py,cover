> """
> RLVR Feedback API Endpoints
  
> Allows users to provide feedback on agent executions for reward verification.
> """
  
! from fastapi import APIRouter, Depends, HTTPException, status
! from pydantic import BaseModel, Field
! from typing import Optional
! import uuid
! from datetime import datetime
  
! from sqlalchemy.ext.asyncio import AsyncSession
! from infrastructure.database import get_db_session
! from security.jwt_auth import get_current_user
! from ml.rlvr.reward_verifier import RewardVerifier, VerificationMethod
! from ml.rlvr.training_collector import TrainingDataCollector
! from ml.rlvr.fine_tuning_orchestrator import FineTuningOrchestrator
! from models.user import User
  
! router = APIRouter(prefix="/api/v1/rlvr", tags=["rlvr", "feedback"])
  
  
  # ============================================================================
  # REQUEST/RESPONSE MODELS
  # ============================================================================
  
! class FeedbackRequest(BaseModel):
!     """User feedback on an agent execution."""
!     execution_id: uuid.UUID
!     thumbs_up: Optional[bool] = None
!     rating: Optional[int] = Field(None, ge=1, le=5)
!     feedback_text: Optional[str] = None
  
  
! class TestResultRequest(BaseModel):
!     """Automated test execution results."""
!     execution_id: uuid.UUID
!     tests_passed: int = Field(ge=0)
!     tests_total: int = Field(gt=0)
!     test_output: Optional[str] = None
  
  
! class CodeAnalysisRequest(BaseModel):
!     """Code quality analysis results."""
!     execution_id: uuid.UUID
!     lint_score: Optional[float] = Field(None, ge=0.0, le=1.0)
!     complexity_score: Optional[float] = Field(None, ge=0.0, le=1.0)
!     security_score: Optional[float] = Field(None, ge=0.0, le=1.0)
  
  
! class TrainingDataCollectionRequest(BaseModel):
!     """Request to collect training data for an agent."""
!     agent_id: uuid.UUID
!     max_examples: int = Field(1000, gt=0, le=10000)
!     days_lookback: int = Field(30, gt=0, le=365)
  
  
! class FineTuningRequest(BaseModel):
!     """Request to start fine-tuning an agent."""
!     agent_id: uuid.UUID
!     provider: str = Field("openai", pattern="^(openai|anthropic|local)$")
!     base_model: Optional[str] = None
!     epochs: Optional[int] = Field(None, ge=1, le=10)
!     learning_rate: Optional[float] = Field(None, gt=0.0)
  
  
  # ============================================================================
  # FEEDBACK ENDPOINTS
  # ============================================================================
  
! @router.post("/feedback/user", status_code=status.HTTP_201_CREATED)
! async def submit_user_feedback(
!     request: FeedbackRequest,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Submit user feedback on an agent execution.
  
!     This creates a reward score based on explicit user feedback.
!     """
!     verifier = RewardVerifier(session)
  
!     try:
!         reward_score = await verifier.verify_execution(
!             execution_id=request.execution_id,
!             verification_method=VerificationMethod.USER_FEEDBACK,
!             thumbs_up=request.thumbs_up,
!             user_rating=request.rating,
!             user_feedback=request.feedback_text,
!             user_id=current_user.id
!         )
  
!         return {
!             "success": True,
!             "reward_score": float(reward_score['reward_score']),
!             "message": "Thank you for your feedback! This helps improve the agent."
!         }
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to process feedback: {str(e)}"
!         )
  
  
! @router.post("/feedback/test-results", status_code=status.HTTP_201_CREATED)
! async def submit_test_results(
!     request: TestResultRequest,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Submit automated test results for an agent execution.
  
!     This creates a reward score based on test pass rate.
!     """
!     verifier = RewardVerifier(session)
  
!     try:
!         reward_score = await verifier.verify_execution(
!             execution_id=request.execution_id,
!             verification_method=VerificationMethod.TEST_EXECUTION,
!             tests_passed=request.tests_passed,
!             tests_total=request.tests_total,
!             test_output=request.test_output
!         )
  
!         return {
!             "success": True,
!             "reward_score": float(reward_score['reward_score']),
!             "tests_passed": request.tests_passed,
!             "tests_total": request.tests_total,
!             "pass_rate": f"{(request.tests_passed / request.tests_total * 100):.1f}%"
!         }
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to process test results: {str(e)}"
!         )
  
  
! @router.post("/feedback/code-analysis", status_code=status.HTTP_201_CREATED)
! async def submit_code_analysis(
!     request: CodeAnalysisRequest,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Submit code quality analysis results for an agent execution.
  
!     This creates a reward score based on code quality metrics.
!     """
!     verifier = RewardVerifier(session)
  
!     try:
!         reward_score = await verifier.verify_execution(
!             execution_id=request.execution_id,
!             verification_method=VerificationMethod.CODE_ANALYSIS,
!             lint_score=request.lint_score,
!             complexity_score=request.complexity_score,
!             security_score=request.security_score
!         )
  
!         return {
!             "success": True,
!             "reward_score": float(reward_score['reward_score']),
!             "code_quality": {
!                 "lint": request.lint_score,
!                 "complexity": request.complexity_score,
!                 "security": request.security_score
!             }
!         }
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to process code analysis: {str(e)}"
!         )
  
  
  # ============================================================================
  # TRAINING DATA COLLECTION
  # ============================================================================
  
! @router.post("/training/collect", status_code=status.HTTP_200_OK)
! async def collect_training_data(
!     request: TrainingDataCollectionRequest,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Collect training examples from verified agent executions.
  
!     This prepares data for fine-tuning.
!     """
!     collector = TrainingDataCollector(session)
  
!     try:
!         result = await collector.collect_training_data(
!             agent_id=request.agent_id,
!             max_examples=request.max_examples,
!             days_lookback=request.days_lookback
!         )
  
!         return {
!             "success": True,
!             **result
!         }
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to collect training data: {str(e)}"
!         )
  
  
! @router.get("/training/stats/{agent_id}")
! async def get_training_stats(
!     agent_id: uuid.UUID,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Get statistics about collected training data for an agent.
!     """
!     collector = TrainingDataCollector(session)
  
!     try:
!         stats = await collector.get_collection_stats(agent_id)
!         return stats
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to get training stats: {str(e)}"
!         )
  
  
  # ============================================================================
  # FINE-TUNING
  # ============================================================================
  
! @router.post("/fine-tune/start", status_code=status.HTTP_202_ACCEPTED)
! async def start_fine_tuning(
!     request: FineTuningRequest,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Start a fine-tuning run for an agent.
  
!     This will train a new version of the agent based on collected feedback.
!     """
!     orchestrator = FineTuningOrchestrator(session)
  
!     try:
          # Prepare hyperparameters
!         hyperparameters = {}
!         if request.epochs:
!             hyperparameters['epochs'] = request.epochs
!         if request.learning_rate:
!             hyperparameters['learning_rate'] = request.learning_rate
  
!         result = await orchestrator.start_fine_tuning(
!             agent_id=request.agent_id,
!             provider=request.provider,
!             base_model=request.base_model,
!             hyperparameters=hyperparameters if hyperparameters else None
!         )
  
!         return {
!             "success": True,
!             "message": "Fine-tuning started successfully",
!             **result
!         }
  
!     except ValueError as e:
!         raise HTTPException(
!             status_code=status.HTTP_400_BAD_REQUEST,
!             detail=str(e)
!         )
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to start fine-tuning: {str(e)}"
!         )
  
  
! @router.get("/fine-tune/status/{run_id}")
! async def get_fine_tuning_status(
!     run_id: uuid.UUID,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Get the status of a fine-tuning run.
!     """
!     try:
!         query = """
!             SELECT
!                 id, agent_id, base_model, provider, status,
!                 progress_percentage, started_at, completed_at,
!                 trained_model_id, error_message
!             FROM fine_tuning_runs
!             WHERE id = :run_id
!         """
  
!         result = await session.execute(query, {"run_id": run_id})
!         row = result.fetchone()
  
!         if not row:
!             raise HTTPException(
!                 status_code=status.HTTP_404_NOT_FOUND,
!                 detail=f"Fine-tuning run {run_id} not found"
!             )
  
!         return {
!             "run_id": str(row[0]),
!             "agent_id": str(row[1]),
!             "base_model": row[2],
!             "provider": row[3],
!             "status": row[4],
!             "progress": row[5],
!             "started_at": row[6].isoformat() if row[6] else None,
!             "completed_at": row[7].isoformat() if row[7] else None,
!             "trained_model_id": row[8],
!             "error_message": row[9]
!         }
  
!     except HTTPException:
!         raise
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to get status: {str(e)}"
!         )
  
  
! @router.post("/fine-tune/deploy/{run_id}", status_code=status.HTTP_200_OK)
! async def deploy_fine_tuned_agent(
!     run_id: uuid.UUID,
!     deploy_to_production: bool = False,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Deploy a fine-tuned agent to production.
  
!     **WARNING**: This will update the agent in production!
!     """
!     orchestrator = FineTuningOrchestrator(session)
  
!     try:
!         result = await orchestrator.deploy_fine_tuned_agent(
!             run_id=run_id,
!             deploy_to_production=deploy_to_production
!         )
  
!         return {
!             "success": True,
!             "message": "Agent deployed successfully",
!             **result
!         }
  
!     except ValueError as e:
!         raise HTTPException(
!             status_code=status.HTTP_400_BAD_REQUEST,
!             detail=str(e)
!         )
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to deploy agent: {str(e)}"
!         )
  
  
  # ============================================================================
  # ANALYTICS
  # ============================================================================
  
! @router.get("/analytics/agent/{agent_id}")
! async def get_agent_analytics(
!     agent_id: uuid.UUID,
!     days: int = 30,
!     current_user: User = Depends(get_current_user),
!     session: AsyncSession = Depends(get_db_session)
! ):
!     """
!     Get RLVR analytics for an agent.
  
!     Shows improvement over time, reward distribution, etc.
!     """
!     try:
          # Get reward score distribution
!         query = """
!             SELECT
!                 DATE(e.created_at) as date,
!                 AVG(r.reward_score) as avg_reward,
!                 COUNT(*) as executions,
!                 SUM(CASE WHEN r.reward_score >= 0.7 THEN 1 ELSE 0 END) as high_reward_count
!             FROM agent_executions e
!             INNER JOIN reward_scores r ON e.id = r.execution_id
!             WHERE e.agent_id = :agent_id
!                 AND e.created_at >= NOW() - INTERVAL ':days days'
!             GROUP BY DATE(e.created_at)
!             ORDER BY date DESC
!         """
  
!         result = await session.execute(query, {"agent_id": agent_id, "days": days})
!         daily_stats = [
!             {
!                 "date": str(row[0]),
!                 "avg_reward": float(row[1]),
!                 "executions": row[2],
!                 "high_reward_count": row[3],
!                 "high_reward_rate": f"{(row[3] / row[2] * 100):.1f}%"
!             }
!             for row in result.fetchall()
!         ]
  
          # Get overall stats
!         overall_query = """
!             SELECT
!                 COUNT(DISTINCT e.id) as total_executions,
!                 AVG(r.reward_score) as avg_reward,
!                 MAX(r.reward_score) as max_reward,
!                 MIN(r.reward_score) as min_reward
!             FROM agent_executions e
!             INNER JOIN reward_scores r ON e.id = r.execution_id
!             WHERE e.agent_id = :agent_id
!                 AND e.created_at >= NOW() - INTERVAL ':days days'
!         """
  
!         overall_result = await session.execute(
!             overall_query, {"agent_id": agent_id, "days": days}
!         )
!         overall_row = overall_result.fetchone()
  
!         return {
!             "agent_id": str(agent_id),
!             "period_days": days,
!             "overall": {
!                 "total_executions": overall_row[0],
!                 "avg_reward": float(overall_row[1]) if overall_row[1] else 0.0,
!                 "max_reward": float(overall_row[2]) if overall_row[2] else 0.0,
!                 "min_reward": float(overall_row[3]) if overall_row[3] else 0.0
!             },
!             "daily_stats": daily_stats
!         }
  
!     except Exception as e:
!         raise HTTPException(
!             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
!             detail=f"Failed to get analytics: {str(e)}"
!         )
