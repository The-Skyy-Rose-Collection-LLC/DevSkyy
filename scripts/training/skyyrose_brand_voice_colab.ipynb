{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkyyRose Brand Voice LLM Training\n",
    "\n",
    "Fine-tune Qwen2.5-1.5B-Instruct on SkyyRose brand voice dataset.\n",
    "\n",
    "**Instructions:**\n",
    "1. Runtime > Change runtime type > T4 GPU\n",
    "2. Run all cells\n",
    "3. Model will be pushed to: huggingface.co/damBruh/skyyrose-brand-voice-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q trl peft transformers datasets accelerate bitsandbytes huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Login to HuggingFace (get token from https://huggingface.co/settings/tokens)\nfrom huggingface_hub import login\nfrom google.colab import userdata\n\n# Use Colab secrets or prompt for token\ntry:\n    hf_token = userdata.get('HF_TOKEN')\nexcept:\n    hf_token = input(\"Enter your HuggingFace token: \")\n\nlogin(token=hf_token)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "DATASET_NAME = \"damBruh/skyyrose-brand-voice-training\"\n",
    "OUTPUT_DIR = \"./skyyrose-brand-voice-llm\"\n",
    "HF_USERNAME = \"damBruh\"\n",
    "\n",
    "print(f\"Loading dataset: {DATASET_NAME}\")\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "print(f\"Dataset loaded: {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization config for efficient training\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    gradient_checkpointing=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"{HF_USERNAME}/skyyrose-brand-voice-llm\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing SFTTrainer...\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving and pushing to Hub...\")\n",
    "trainer.save_model()\n",
    "trainer.push_to_hub()\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"Model available at: https://huggingface.co/{HF_USERNAME}/skyyrose-brand-voice-llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=f\"{HF_USERNAME}/skyyrose-brand-voice-llm\", device_map=\"auto\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are SkyyRose's brand voice - a luxury streetwear brand from Oakland, California.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a product description for a limited edition rose gold bomber jacket.\"}\n",
    "]\n",
    "\n",
    "response = pipe(messages, max_new_tokens=200)\n",
    "print(response[0]['generated_text'][-1]['content'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}